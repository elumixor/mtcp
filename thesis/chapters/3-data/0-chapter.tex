\chapter{The Large Hadron Collider and the ATLAS Detector}

\section{The Large Hadron Collider}

The Large Hadron Collider (LHC), located at CERN near Geneva, Switzerland, is currently the world's largest and most
powerful particle accelerator. It was designed to facilitate high-energy proton-proton and heavy-ion collisions with the
objective of probing the fundamental structure of the universe.

The LHC, a 27 km circumference ring situated 100 meters underground, operates by accelerating two beams of protons to
near the speed of light in opposite directions. These beams are then steered into collision at four interaction points
where the LHC's main experiments, ATLAS, CMS, ALICE, and LHCb, are situated.

\section{The ATLAS Detector}

The ATLAS (A Toroidal LHC ApparatuS) detector, one of the two general-purpose detectors at the LHC, is designed to
measure a broad range of particles and phenomena produced in the LHC's proton-proton collisions. With a length of 44
meters and a diameter of 25 meters, it's a massive instrument consisting of several layers each dedicated to detecting
different types of particles.

From innermost to outermost, the main components of the ATLAS detector are the Inner Detector for tracking, the
Electromagnetic and Hadronic Calorimeters for energy measurements, and the Muon Spectrometer for detecting muons.
Surrounding the entire apparatus is a complex magnet system that bends the trajectories of charged particles, allowing
for the determination of their momentum.

\section{Data Acquisition and Processing}

When proton-proton collisions occur in the ATLAS detector, the produced particles traverse the detector layers, leaving
behind signals that are transformed into digital data. Given the LHC's high collision rate, it's crucial to select only
the potentially interesting events for further analysis, a task performed by the ATLAS trigger system.

The trigger system operates in several levels, with each level applying increasingly precise selection criteria to
reduce the data rate. After passing the trigger system, the selected collision events are stored for offline analysis.

The raw data then undergoes a processing stage known as reconstruction. This process translates the raw detector signals
into identifiable physics objects such as electrons, muons, photons, and jets.

\section{Data Analysis and Event Selection}

The primary objective of data analysis in particle physics is to extract interesting physics events from a vast amount
of collected data. The initial stage of data analysis involves event selection, where specific criteria are applied to
separate potential signal events from background noise.

In the context of our ttH analysis in the 2lSS1Tau channel, event selection criteria include the identification of two
same-sign leptons and one hadronically decaying tau lepton. Moreover, additional conditions may be applied to identify
the presence of jets, especially b-jets, which are indicative of top quark decay.

However, even with strict event selection criteria, a significant number of background events can mimic the ttH signal.
The most common background processes include ttW and ttZ events, Drell-Yan events, and others. These backgrounds are
estimated using a combination of data-driven methods and Monte Carlo simulations and are subtracted from the observed
data to reveal the potential ttH signal.

\section{Simulated Data and Event Weighting}

Simulated data plays a critical role in particle physics experiments. To interpret the experimental results, we need to
understand what we would expect to observe under different theoretical models. This is accomplished through detailed
simulations of the processes of interest, as well as the response of the detector to these processes.

Monte Carlo (MC) methods are commonly used for these simulations. The MC simulation provides a probabilistic
interpretation of the quantum mechanical processes that occur during particle collisions, as well as the subsequent
decay and detection of the produced particles. However, MC simulations start from an idealized condition, assuming
perfect detector operation and ignoring many real-world factors that can affect the data.

To align the MC simulated data with the real data, it is necessary to apply event weights. Event weighting is a
technique used to correct the simulated distributions for known differences between the simulation and the real data.

Event weights can account for a variety of effects:

Luminosity: The total number of simulated events often does not correspond to the luminosity of the real data. Events
are therefore weighted to correspond to the correct integrated luminosity. If $L_{data}$ is the integrated luminosity of
the data and $L_{MC}$ is the integrated luminosity of the MC sample, then the luminosity weight for an event is $w_{L} =
    L_{data}/L_{MC}$.

Cross-Section: Different processes have different probabilities (cross-sections) of occurring. The ratio of the
cross-sections in data and simulation $\sigma_{data}/\sigma_{MC}$ is used as a weight.

Detector Effects: The detector response is not always perfectly simulated. Therefore, weights are applied to correct for
known discrepancies in detector efficiencies and energy resolutions between the data and the simulation.

Pileup: Pileup refers to additional proton-proton collisions that occur simultaneously with the event of interest.
Pileup can significantly affect the event reconstruction. Pileup weights are used to match the pileup distribution in
the data.

Higher-order corrections: Theoretical predictions often include higher-order corrections, known as K-factors, to account
for processes beyond the leading-order approximation used in the simulation.

In mathematical terms, the total weight $w_{total}$ for an event can be written as the product of individual weights:

\begin{equation}
    w_{\text{total}} = w_{L} w_{\sigma} w_{\text{detector}} w_{\text{pileup}} w_{\text{K-factor}}
\end{equation}

Event weights are essential for ensuring that the simulated events accurately represent the conditions of the actual
experiment. These weights allow us to make meaningful comparisons between the data and theoretical predictions, and are
a crucial part of the analysis in high-energy physics.


\input{chapters/3-data/v8/0-section.tex}
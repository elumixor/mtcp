\glsreset{mc}

\section[Monte Carlo Simulation]{\gls{mc} Simulation}
\label{sec:mc}

To be able to train classifiers for the precise identification of \tth events, we must adopt a method that transcends
mere observation of final state particles. Our particle accelerator, engineered to collide particles and equipped with
advanced detectors, can capture various attributes of these final states, including their energy, momentum, and type.

The obstacle we face is the intrinsic limitation of detecting only the final state particles and not the elusive
intermediate processes. Since the intermediate particles remain undetectable, due to their extremely short lifetimes,
limitations in current detection technology, the inherent complexity of the interactions, and the energy levels at which
they exist, we must reconstruct the entire collision event from the observable final state particles.

This problem can be elegantly formulated as a supervised learning task (see \autoref{sec:formulation}). Although
clustering presents an alternative, supervised learning often proves to be more efficient and is favored when the
conditions allow for its use (see \appref{appendix:why-supervised} for more details).

By employing a theoretical model with established branching rules, we construct a \gls{mc} simulation.  We use software
like Pythia\footnote{\url{https://pythia.org/}} to generate a labeled dataset where the
final state particles and their properties are the features, and the intermediate processes, such as \tth or \ttw, are
known and are thus assigned as the corresponding labels.

A vital aspect of our simulation is its adaptability to various detector and accelerator configurations. This ensures an
accurate representation, capturing not only the fundamental physical processes but also the specific characteristics of
how these processes are observed in a real-world particle accelerator environment.

This simulation relies heavily on having an accurate theoretical model and precise modeling of various technical aspects
of the detectors. Recognizing that the simulation may have imperfections, we engage in an iterative process that
involves comparing the simulated results with real data, finding and accounting for any discrepancies, and producing a
new more refined and accurate version of the simulated dataset\footnote{This work was done on the version 8 (v0801) of
    the n-tuples. \appref{appendix:dsids} shows list of files for each process.}.

\subsection{Event Weighting}

The \tth process is very rare and accounts for only about 1\% of all Higgs production. This results in a very low number of
signal events, and, as noted before, training on such a small dataset is practically not tractable. To alleviate this
difficulty, more signal events are explicitly generated.

However, this leads to a very different distribution than the one observed in the real data. To align the \gls{mc}
simulation with the real, the weight $w_i$ is applied to each event $i$. This weight is essentially the estimate of the
probability of the event $i$ occurring in the real data, also given specific detector configuration.

Various factors contribute to the weight of an event. The most important ones are the luminosity, that is different for
different runs of the \gls{lhc}, and the cross-section. We provide the complete formula in
\appref{appendix:weights}.

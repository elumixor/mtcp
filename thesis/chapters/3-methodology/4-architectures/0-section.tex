\section{Architectures and Optimization Techniques}

This section covers the classifier architectures and optimization techniques we employed in our research. As a baseline
model, we used an adaptation of the \glspl{resnet} to the tabular data, inspired by \cite{tabular}. The primary model
that has shown the best results was the \gls{ftt}, also adopted from \cite{tabular}. The process of training these
models and the optimization techniques used to improve their performance is described in the subsequent sections.

\input{chapters/3-methodology/4-architectures/1-previous-works}
\input{chapters/3-methodology/4-architectures/2-resnet}
\input{chapters/3-methodology/4-architectures/3-embedding}
\input{chapters/3-methodology/4-architectures/4-transformer}
\input{chapters/3-methodology/4-architectures/5-dropout}
\input{chapters/3-methodology/4-architectures/6-dropping-cuts}
\input{chapters/3-methodology/4-architectures/7-reduced-training-set}
\input{chapters/3-methodology/4-architectures/8-weights}
\input{chapters/3-methodology/4-architectures/9-classes-fine-tuning}
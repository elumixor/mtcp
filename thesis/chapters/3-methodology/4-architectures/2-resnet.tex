\subsection[resnet]{\gls{resnet}}
\label{sec:resnet}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{figures/resnet.pdf}
    \caption{Resnet architecture.}
    \label{fig:resnet_architecture}
\end{figure}

We compare the staged network to a slightly improved version of \gls{mlp} that introduces residual/skip
connections between the layers (see \autoref{fig:resnet_architecture}) proposed by \cite{resnet}.
Those connections improve the training of deep neural networks, as the gradients can flow unimpeded back to the first
layers. This helps combat the vanishing gradients problem. We can formalize this as in
\cite{ft-transformer}:


{\fontsize{11}{10}\selectfont
\begin{align}
    \text{ResNet(x)}      & = \text{Prediction}(\text{ResNetBlock}(\dots(\text{ResNetBlock}(\text{Linear}(\text{Embed}(x)))))) \\
    \text{ResNetBlock(x)} & = x + \text{Dropout}(\text{Linear}(\text{LayerNorm}(\sigma(x))))                                   \\
    \text{Prediction}(x)  & = \text{Linear}(\text{LayerNorm}(\sigma(x)))
\end{align}
}

ResNets are very fast to train, and more sample efficient than \glspl{mlp}.

% The best results obtained with Resnets were 85\% accuracy,
% 0.85 $\text{AUC}_\text{mean}$ and 0.85 $\text{AUC}_{t\bar{t}H}$ (see \autoref{fig:resnet_results}).

While keeping the number of trainable parameters the same, it's better to have deeper networks than wider networks.
Although wide NNs are fast to train, they are extremely prone to overfitting, as the starting layers essentially
memorize the training data.


We introduce a few other changes to the training procedure:

\begin{enumerate}
    \item We use a \verb|AdamW| optimizer \cite{adamw}
    \item We use \verb|GELU| activation \cite{gelu}
    \item Similarly, for the continuous feature, the invalid/missing values are replaced with learnable parameters.
    \item We introduce \verb|LayerNorm| \cite{layernorm} before each \verb|Linear| layer.
\end{enumerate}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{figures/resnet_results.pdf}
    \caption{Resnet results.}
    \label{fig:resnet_results}
\end{figure}


